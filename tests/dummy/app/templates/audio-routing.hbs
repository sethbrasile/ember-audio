<div class="content">
  <h1>Audio Routing</h1>

  <button class="btn btn-primary" type="button" {{action "playSound"}}>Play Sound</button>
  <button class="btn {{if distortionEnabled "" "btn-success"}}" type="button" {{action "toggleDistortion"}}>
    Turn {{if distortionEnabled "Off" "On"}} Distortion
  </button>
</div>

<div class="content">
  <p>
    The signal path in the Web Audio API works by allowing one to stitch
    together various audio "nodes." An audio node works just like a guitar pedal;
    It has an input, it does some stuff to whatever goes into that input, and
    it has an output.
  </p>
</div>

<div class="content">
  <p>
    By default, a <code>Sound</code> instance is routed through 4 audio nodes:
  </p>

  <ol>
    <li>
      <code>Source</code> - It's input is some sort of audio source; Sound
      loaded from a file, a synthesizer oscillator, or input from a user's
      microphone. It's output is digital audio data that the other audio
      nodes understand.
    </li>
    <li>
      <code>Gain</code> - This node allows one to adjust the
      <a href="http://www.offbeatband.com/2009/08/the-difference-between-gain-volume-level-and-loudness/">
        gain
      </a>
      of the audio data that is routed through it.
    </li>
    <li>
      <code>Panner</code> - This node allows one to control the stereo pan
      position (left or right) of the audio data that is routed through it.
    </li>
    <li>
      <code>Destination</code> - This node routes any audio data that is routed
      through it, to the end user's audio output.
    </li>
  </ol>
</div>

<div class="content">
  <p>
    The nodes are connected automatically, in the same order that they exist
    in the <code>connections</code> array. For the example above (the default
    case) they are connected like: <code>Source</code> -> <code>Gain</code>
    -> <code>Panner</code> -> <code>Destination</code>
  </p>
</div>

<div class="content">
  <p class="well">
    There are many more <code>AudioNode</code> types provided by the Web Audio
    API than the ones that are represented here. Take a look at the
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">
      Web Audio API Documentation
    </a>
    to learn about all of the available <code>AudioNode</code> types.
  </p>
</div>

<div class="content">
  <p>
    It is possible to customize routing by adding and removing audio nodes from
    a <code>Sound</code> instance's <code>connections</code> array.
  </p>

  <p>
    The <code>connections</code> array is an <code>Ember.MutableArray</code>
    so it is easily manipulated using it's prototype methods such as
    <code>insertAt</code> and <code>removeAt</code>.
  </p>

  <p>
    A <code>Sound</code> instance also has a convenience method called
    <code>removeConnection</code> that allows one to remove a connection by it's
    <code>name</code>.
  </p>
</div>

<div class="content">
  <CodeBlock @language="handlebars">
    &lt;button class="btn btn-primary" &#123;{action "playSound"}}>Play Sound&lt;/button>
    &lt;button class="btn &#123;{if distortionEnabled "btn-warning" "btn-success"}}" &#123;{action "toggleDistortion"}}>
      Turn &#123;{if distortionEnabled "Off" "On"}} Distortion
    &lt;/button>
  </CodeBlock>

  <CodeBlock @language="javascript">
    import Ember from 'ember';
    import { Connection } from 'ember-audio';

    export default Ember.Whatever.extend({
      audio: Ember.inject.service(),
      distortionEnabled: false,

      initAudioFile: Ember.on('init', function() {
        // Eb5.mp3 is an mp3 file located in the "public" folder
        this.get('audio').load('/ember-audio/Eb5.mp3').asSound('piano-note').then((note) => {

          // Create the connection and insert it into the note's connections array
          note.get('connections').insertAt(1, Connection.create({
            name: 'distortionNode',
            source: 'audioContext',
            createCommand: 'createWaveShaper'
          }));

          this.set('note', note);
        });
      }),

      _makeDistortionCurve(amount) {
        // I stole this straight from the Mozilla Web Audio API docs site
        const k = typeof amount === 'number' ? amount : 50;
        const n_samples = 44100;
        const curve = new Float32Array(n_samples);
        const deg = Math.PI / 180;

        for (let i = 0; i &lt; n_samples; ++i) {
          let x = i * 2 / n_samples - 1;
          curve[i] = ( 3 + k ) * x * 20 * deg / ( Math.PI + k * Math.abs(x) );
        }

        return curve;
      },

      _addDistortion() {
        const curve = this._makeDistortionCurve(400);
        const note = this.get('note');

        this.set('distortionEnabled', true);

        // lower note's gain because distorted signal has much more apparent volume
        note.changeGainTo(0.1).from('ratio');

        // Set distortionNode's curve to enable distortion
        note.getNodeFrom('distortionNode').curve = curve;
      },

      _removeDistortion() {
        const note = this.get('note');

        this.set('distortionEnabled', false);

        // raise note's gain because clean signal has much less apparent volume
        note.changeGainTo(1).from('ratio');

        // Set distortionNode's curve to an empty Float32Array to disable distortion
        note.getNodeFrom('distortionNode').curve = new Float32Array();
      },

      actions: {
        playSound() {
          this.get('note').play();
        },

        toggleDistortion() {
          if (this.get('distortionEnabled')) {
            this._removeDistortion();
          } else {
            this._addDistortion();
          }
        }
      }
    });
  </CodeBlock>
</div>
